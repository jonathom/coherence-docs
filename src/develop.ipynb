{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58bb923-5f27-4e4d-a3a6-281d240734de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from terracatalogueclient import Catalogue\n",
    "import datetime as dt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sys, os\n",
    "\n",
    "from util import suppress_stdout, create_gpd_for_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcb6103b-e1b9-4d34-8e4d-18e3c49239ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting search for scenes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/geopandas/base.py:35: UserWarning: GeoSeries crs mismatch: EPSG:4326 and {'init': 'epsg:4326'}\n",
      "  right.crs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene  1D76 , IW3, has  10  bursts.\n",
      "scene  0A0F , IW2, has  10  bursts.\n",
      "scene  B9E7 , IW3, has  10  bursts.\n",
      "scene  9046 , IW2, has  10  bursts.\n",
      "scene  83DA , IW1, has  12  bursts.\n",
      "scene  83DA , IW2, has  12  bursts.\n",
      "scene  83DA , IW3, has  13  bursts.\n",
      "scene  E320 , IW1, has  10  bursts.\n",
      "nothing added\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "def create_reference_scene_json(start, end, aoi_file: str = None, bursts_file: str = None):\n",
    "    \"\"\"Create a GeoJSON that contains a set of Sentinel 1 reference scenes that are needed as common coregister-references.\n",
    "    \n",
    "    This function employs some tests to make sure every individual scene is only covered once. \n",
    "    However the file coming out of this should be checked one in a while.\n",
    "    \n",
    "    :param start: The start time of the search\n",
    "    :param end: The end time of the search\n",
    "    :param aoi_file: AOI file to limit the search\n",
    "    :param bursts_file: existing .geojson file with reference scenes\n",
    "    \"\"\"\n",
    "    \n",
    "    # input checks\n",
    "    timediff = start - end\n",
    "    if not timediff == dt.timedelta(-12):\n",
    "        print(\"[CAUTION]: For full coverage, a 12 day timedelta is needed.\")\n",
    "    \n",
    "    if os.path.isfile(aoi_file):\n",
    "        aoi = gpd.read_file(aoi_file)\n",
    "    else:\n",
    "        print(\"[ERROR]: no aoi_file given\")\n",
    "        return\n",
    "    \n",
    "    ref_inter_bursts_file = bursts_file\n",
    "    if os.path.isfile(ref_inter_bursts_file):\n",
    "        ref_inter_bursts = gpd.read_file(ref_inter_bursts_file)\n",
    "        create_new_file = False\n",
    "    else:\n",
    "        print(\"ref_inter_bursts_file not found\")\n",
    "        create_new_file = True\n",
    "\n",
    "    print(\"starting search for scenes...\")\n",
    "\n",
    "    catalogue = Catalogue()\n",
    "\n",
    "    cat = catalogue.get_products(\n",
    "        \"urn:eop:VITO:CGS_S1_SLC_L1\",\n",
    "        start = start,\n",
    "        end = end\n",
    "        # , geometry =  WKT string or shapely geom\n",
    "    )\n",
    "\n",
    "    s1a = []\n",
    "\n",
    "    for p in cat:\n",
    "        path = p.data[0].href \n",
    "        iw_index = path.index(\"IW\")\n",
    "        vm_path = \"/data/MTDA/CGS_S1/CGS_S1_SLC_L1/\" + path[iw_index:]\n",
    "\n",
    "        # make swath geometry and add basic info to df\n",
    "        ana_split = create_gpd_for_scene(vm_path, make_regular = True)\n",
    "\n",
    "        # append to list based on satellite\n",
    "        if ana_split[\"sensor\"].iloc[0] == \"S1A\":\n",
    "\n",
    "            # AOI INTERSECTION\n",
    "            # create boolean of which bursts intersect with aoi and which dont\n",
    "            intersects = ana_split.intersects(aoi.iloc[0][\"geometry\"])\n",
    "            # keep only those bursts that intersect with aoi\n",
    "            intersecting_bursts = ana_split[intersects]\n",
    "\n",
    "            if not intersecting_bursts.empty:\n",
    "\n",
    "                # CHECK IF EXISTS\n",
    "                rel_o = intersecting_bursts.iloc[0][\"rel_orbit\"]\n",
    "                o_dir = intersecting_bursts.iloc[0][\"orbit_direction\"]\n",
    "\n",
    "                # if a file already exists\n",
    "                if not create_new_file:\n",
    "                    # search in existing table for bursts of the same relative orbit and orbit direction\n",
    "                    check = ref_inter_bursts.loc[(ref_inter_bursts[\"rel_orbit\"] == rel_o) & (ref_inter_bursts[\"orbit_direction\"] == o_dir)]\n",
    "                    # if some are found:\n",
    "                    if not check.empty:\n",
    "                        # intersect with the new bursts\n",
    "                        intersec = gpd.overlay(intersecting_bursts, check, how = \"intersection\") # .to_file(\"intersection_test_\" + ana_split.iloc[0][\"id\"] + \".geojson\", driver = \"GeoJSON\")\n",
    "                        intersec[\"area\"] = intersec.to_crs({'init': 'epsg:32631'}).area\n",
    "                        # calculate the overall intersecting area\n",
    "                        intersec_area = intersec[\"area\"].sum()\n",
    "                    else:\n",
    "                        # if none are found, intersecting area is 0\n",
    "                        intersec_area = 0\n",
    "\n",
    "                    # calculate area of new bursts\n",
    "                    new_scene_area = intersecting_bursts.to_crs({'init': 'epsg:32631'}).area.sum()\n",
    "                    # calculate ratio between the two areas\n",
    "                    ratio = intersec_area / new_scene_area\n",
    "\n",
    "                # otherwise add all, of course\n",
    "                else:\n",
    "                    ratio = 0\n",
    "\n",
    "                if ratio < 0.9:\n",
    "                    s1a.append(intersecting_bursts)\n",
    "\n",
    "    if s1a:\n",
    "        s1a_df = gpd.GeoDataFrame(pd.concat(s1a, ignore_index = True), crs=s1a[0].crs)\n",
    "\n",
    "        # if a file exists, add to it and rewrite\n",
    "        if not create_new_file:\n",
    "            print(len(s1a_df), \" bursts added.\")\n",
    "            s1a_df = ref_inter_bursts.append(s1a_df, sort = False)\n",
    "        else:\n",
    "            print(len(s1a_df), \" bursts found.\")\n",
    "\n",
    "        # create empty dictionairy for the mapping ID - frame number\n",
    "        relative_frames = {}\n",
    "        # initiate column\n",
    "        s1a_df[\"rel_frame\"] = 0\n",
    "        # init frame number\n",
    "        fnr = int(1)\n",
    "\n",
    "        # TODO heard that iterrows() is slow, not sure how I could improve here\n",
    "        for index, row in s1a_df.iterrows():\n",
    "            if row[\"id\"] in relative_frames:\n",
    "                s1a_df.at[index, \"rel_frame\"] = relative_frames[row[\"id\"]]\n",
    "            else:\n",
    "                s1a_df.at[index, \"rel_frame\"] = fnr\n",
    "                relative_frames[row[\"id\"]] = fnr\n",
    "                fnr += 1\n",
    "\n",
    "        # write bursts\n",
    "        s1a_df.to_file(\"reference_bursts.geojson\", driver = \"GeoJSON\")\n",
    "        # extract scenes and write\n",
    "        s1a_df.dissolve([\"id\"], as_index = False).to_file(\"reference_scenes.geojson\", driver = \"GeoJSON\")\n",
    "\n",
    "    elif not s1a:\n",
    "        print(\"nothing added\")\n",
    "    else:\n",
    "        print(\"error\")\n",
    "\n",
    "    # gpd.overlay(aoi, s1a_df, how = \"intersection\").to_file(\"test2.geojson\", driver = \"GeoJSON\")\n",
    "\n",
    "    print(\"end\")\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "# input time frame in which reference scenes should be defined\n",
    "# this should be no longer than 12 days! after 12 days, orbits of a single satellite repeat and ambiguities arise\n",
    "# My use case was to collect the base scenes from 1.10 - 12.10.2021, and to add some scenes over france from oct 2020 later on\n",
    "start = dt.date(2020, 10, 1)\n",
    "end = dt.date(2020, 10, 13)\n",
    "bursts_file = \"/home/jonathanbahlmann/Public/coherence-docs/src/reference_bursts.geojson\"\n",
    "aoi_file = \"/home/jonathanbahlmann/Public/coherence-docs/aoi/belgium_france.geojson\"\n",
    "\n",
    "create_reference_scene_json(start = start, end = end, aoi_file = aoi_file, bursts_file = bursts_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8850da-db2a-4a26-869f-29e7cf9289cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b33fab3-cef6-4cac-afb1-e56d2677beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from util import list_days\n",
    "\n",
    "# 2021/07/03 - 2021/09/10\n",
    "start  = \"2021/07/03\"\n",
    "end = \"2021/11/10\"\n",
    "path = \"/data/MTDA/CGS_S1/CGS_S1_SLC_L1/IW/DV/\"\n",
    "\n",
    "def list_products_by_time(start, end, path = \"/data/MTDA/CGS_S1/CGS_S1_SLC_L1/IW/DV/\"):\n",
    "    s_month = int(start[5:7])\n",
    "    e_month = int(end[5:7])\n",
    "    s_day = int(start[8:])\n",
    "    e_day = int(end[8:])\n",
    "\n",
    "    start_folder = path + start[0:7] # year and month, no /\n",
    "    end_folder = path + end[0:7]\n",
    "\n",
    "    # if only in one month\n",
    "    if s_month == e_month:\n",
    "        start_folder_days = os.listdir(start_folder)[s_day-1:e_day] # list days, from start day : end day\n",
    "        list_of_products = list_days(list_of_days = start_folder_days, month_path = start_folder)\n",
    "    # no in between month\n",
    "    elif s_month + 1 == e_month:\n",
    "        start_folder_days = os.listdir(start_folder)[s_day-1:] # list days, from start day\n",
    "        end_folder_days = os.listdir(end_folder)[:e_day]\n",
    "        list_of_products = list_days(start_folder_days, start_folder) + list_days(end_folder_days, end_folder)\n",
    "    # with month in between\n",
    "    elif s_month +1 < e_month:\n",
    "        start_folder_days = os.listdir(start_folder)[s_day-1:]\n",
    "        end_folder_days = os.listdir(end_folder)[:e_day]\n",
    "        list_of_products = list_days(start_folder_days, start_folder) + list_days(end_folder_days, end_folder)\n",
    "\n",
    "        for i in range(s_month+1,e_month):\n",
    "            if i < 10:\n",
    "                month = \"0\" + str(i)\n",
    "            elif i >= 10:\n",
    "                month = str(i)\n",
    "\n",
    "            month_path = os.path.join(path, start[0:5], month)\n",
    "            month_days_list = os.listdir(month_path)\n",
    "            month_prod_list = list_days(month_days_list, month_path)\n",
    "            list_of_products.extend(month_prod_list)\n",
    "        \n",
    "    return list_of_products\n",
    "\n",
    "# print(list_days([\"01\", \"02\", \"03\"], path + \"2021/08\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75c026ec-fa6a-4662-8afd-07241cb079db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_bursts_file not found\n",
      "['6471']\n",
      "['3785']\n",
      "['ACC4']\n",
      "['7BC8']\n",
      "['4712', '9F0A']\n",
      "['7BC8', '9F0A']\n",
      "['1F6C']\n",
      "['7E94']\n",
      "['1F6C']\n",
      "[]\n",
      "['AAC4', '3F3B']\n",
      "['AAC4']\n",
      "[]\n",
      "['FB38']\n",
      "['14F6']\n",
      "['314F']\n",
      "['7AA0']\n",
      "['7AA0', 'A8C7']\n",
      "['A8C7']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from util import create_gpd_for_scene\n",
    "\n",
    "products = list_products_by_time(start = \"2021/09/06\", end = \"2021/09/10\")\n",
    "# we get 3 products for that day\n",
    "prod_file = \"\"\n",
    "\n",
    "if os.path.isfile(prod_file):\n",
    "    prod_gpd = gpd.read_file(prod_file)\n",
    "    create_new_file = False\n",
    "else:\n",
    "    print(\"ref_bursts_file not found\")\n",
    "    create_new_file = True\n",
    "    \n",
    "ref_bursts = gpd.read_file(\"reference_bursts.geojson\")\n",
    "    \n",
    "for path in products:\n",
    "    # make swath geometry and add basic info to df\n",
    "    scene_bursts = create_gpd_for_scene(path)\n",
    "    \n",
    "    if create_new_file: #not create_new_file:\n",
    "        # check every scene\n",
    "        pass\n",
    "    \n",
    "        # check which bursts are eligible for processing (overlap AOI) OR search directly for ref scene\n",
    "        ref_scene_id = search_for_reference(scene_bursts, ref_bursts)\n",
    "        print(ref_scene_id)\n",
    "        \n",
    "        # can come back empty, len 1 or len 2\n",
    "        \n",
    "        \n",
    "        # check if all bursts are in the file already\n",
    "        \n",
    "        # if yes, go ahead\n",
    "        \n",
    "        # if no, process\n",
    "    \n",
    "    \n",
    "    \n",
    "    else:\n",
    "        # add all scenes\n",
    "        pass\n",
    "    \n",
    "    # write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42cda88b-412b-479a-ad2e-3a2ace302bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eb4fde56-a264-4379-9107-7ddcef86f5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/hello'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(\"/data\", \"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8cebf6b2-ffd1-447f-b3b0-4e19e0d4c25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01', '03'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [\"01\", \"02\"]\n",
    "l2 = [\"01\", \"03\"]\n",
    "set(l1) == set(l2)\n",
    "set(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda69e1-6362-4658-9779-3ea1b81bc6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
