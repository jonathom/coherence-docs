{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58bb923-5f27-4e4d-a3a6-281d240734de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from terracatalogueclient import Catalogue\n",
    "import datetime as dt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sys, os\n",
    "\n",
    "from util import suppress_stdout, create_gpd_for_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb6103b-e1b9-4d34-8e4d-18e3c49239ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reference_scene_json(start, end, aoi_file: str = None, bursts_file: str = None):\n",
    "    \"\"\"Create a GeoJSON that contains a set of Sentinel 1 reference scenes that are needed as common coregister-references.\n",
    "    \n",
    "    This function employs some tests to make sure every individual scene is only covered once. \n",
    "    However the file coming out of this should be checked one in a while.\n",
    "    \n",
    "    :param start: The start time of the search\n",
    "    :param end: The end time of the search\n",
    "    :param aoi_file: AOI file to limit the search\n",
    "    :param bursts_file: existing .geojson file with reference scenes\n",
    "    \"\"\"\n",
    "    \n",
    "    # input checks\n",
    "    timediff = start - end\n",
    "    if not timediff == dt.timedelta(-12):\n",
    "        print(\"[CAUTION]: For full coverage, a 12 day timedelta is needed.\")\n",
    "    \n",
    "    if os.path.isfile(aoi_file):\n",
    "        aoi = gpd.read_file(aoi_file)\n",
    "    else:\n",
    "        print(\"[ERROR]: no aoi_file given\")\n",
    "        return\n",
    "    \n",
    "    ref_inter_bursts_file = bursts_file\n",
    "    if os.path.isfile(ref_inter_bursts_file):\n",
    "        ref_inter_bursts = gpd.read_file(ref_inter_bursts_file)\n",
    "        create_new_file = False\n",
    "    else:\n",
    "        print(\"ref_inter_bursts_file not found\")\n",
    "        create_new_file = True\n",
    "\n",
    "    print(\"starting search for scenes...\")\n",
    "\n",
    "    catalogue = Catalogue()\n",
    "\n",
    "    cat = catalogue.get_products(\n",
    "        \"urn:eop:VITO:CGS_S1_SLC_L1\",\n",
    "        start = start,\n",
    "        end = end\n",
    "        # , geometry =  WKT string or shapely geom\n",
    "    )\n",
    "\n",
    "    s1a = []\n",
    "\n",
    "    for p in cat:\n",
    "        path = p.data[0].href \n",
    "        iw_index = path.index(\"IW\")\n",
    "        vm_path = \"/data/MTDA/CGS_S1/CGS_S1_SLC_L1/\" + path[iw_index:]\n",
    "\n",
    "        # make swath geometry and add basic info to df\n",
    "        ana_split = create_gpd_for_scene(vm_path, make_regular = True)\n",
    "\n",
    "        # append to list based on satellite\n",
    "        if ana_split[\"sensor\"].iloc[0] == \"S1A\":\n",
    "\n",
    "            # AOI INTERSECTION\n",
    "            # create boolean of which bursts intersect with aoi and which dont\n",
    "            intersects = ana_split.intersects(aoi.iloc[0][\"geometry\"])\n",
    "            # keep only those bursts that intersect with aoi\n",
    "            intersecting_bursts = ana_split[intersects]\n",
    "\n",
    "            if not intersecting_bursts.empty:\n",
    "\n",
    "                # CHECK IF EXISTS\n",
    "                rel_o = intersecting_bursts.iloc[0][\"rel_orbit\"]\n",
    "                o_dir = intersecting_bursts.iloc[0][\"orbit_direction\"]\n",
    "\n",
    "                # if a file already exists\n",
    "                if not create_new_file:\n",
    "                    # search in existing table for bursts of the same relative orbit and orbit direction\n",
    "                    check = ref_inter_bursts.loc[(ref_inter_bursts[\"rel_orbit\"] == rel_o) & (ref_inter_bursts[\"orbit_direction\"] == o_dir)]\n",
    "                    # if some are found:\n",
    "                    if not check.empty:\n",
    "                        # intersect with the new bursts\n",
    "                        intersec = gpd.overlay(intersecting_bursts, check, how = \"intersection\") # .to_file(\"intersection_test_\" + ana_split.iloc[0][\"id\"] + \".geojson\", driver = \"GeoJSON\")\n",
    "                        intersec[\"area\"] = intersec.to_crs({'init': 'epsg:32631'}).area\n",
    "                        # calculate the overall intersecting area\n",
    "                        intersec_area = intersec[\"area\"].sum()\n",
    "                    else:\n",
    "                        # if none are found, intersecting area is 0\n",
    "                        intersec_area = 0\n",
    "\n",
    "                    # calculate area of new bursts\n",
    "                    new_scene_area = intersecting_bursts.to_crs({'init': 'epsg:32631'}).area.sum()\n",
    "                    # calculate ratio between the two areas\n",
    "                    ratio = intersec_area / new_scene_area\n",
    "\n",
    "                # otherwise add all, of course\n",
    "                else:\n",
    "                    ratio = 0\n",
    "\n",
    "                if ratio < 0.9:\n",
    "                    s1a.append(intersecting_bursts)\n",
    "\n",
    "    if s1a:\n",
    "        s1a_df = gpd.GeoDataFrame(pd.concat(s1a, ignore_index = True), crs=s1a[0].crs)\n",
    "\n",
    "        # if a file exists, add to it and rewrite\n",
    "        if not create_new_file:\n",
    "            print(len(s1a_df), \" bursts added.\")\n",
    "            s1a_df = ref_inter_bursts.append(s1a_df, sort = False)\n",
    "        else:\n",
    "            print(len(s1a_df), \" bursts found.\")\n",
    "\n",
    "        # create empty dictionairy for the mapping ID - frame number\n",
    "        relative_frames = {}\n",
    "        # initiate column\n",
    "        s1a_df[\"rel_frame\"] = 0\n",
    "        # init frame number\n",
    "        fnr = int(1)\n",
    "\n",
    "        # TODO heard that iterrows() is slow, not sure how I could improve here\n",
    "        for index, row in s1a_df.iterrows():\n",
    "            if row[\"id\"] in relative_frames:\n",
    "                s1a_df.at[index, \"rel_frame\"] = relative_frames[row[\"id\"]]\n",
    "            else:\n",
    "                s1a_df.at[index, \"rel_frame\"] = fnr\n",
    "                relative_frames[row[\"id\"]] = fnr\n",
    "                fnr += 1\n",
    "\n",
    "        # write bursts\n",
    "        s1a_df.to_file(\"reference_bursts.geojson\", driver = \"GeoJSON\")\n",
    "        # extract scenes and write\n",
    "        s1a_df.dissolve([\"id\"], as_index = False).to_file(\"reference_scenes.geojson\", driver = \"GeoJSON\")\n",
    "\n",
    "    elif not s1a:\n",
    "        print(\"nothing added\")\n",
    "    else:\n",
    "        print(\"error\")\n",
    "\n",
    "    # gpd.overlay(aoi, s1a_df, how = \"intersection\").to_file(\"test2.geojson\", driver = \"GeoJSON\")\n",
    "\n",
    "    print(\"end\")\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "# input time frame in which reference scenes should be defined\n",
    "# this should be no longer than 12 days! after 12 days, orbits of a single satellite repeat and ambiguities arise\n",
    "# My use case was to collect the base scenes from 1.10 - 12.10.2021, and to add some scenes over france from oct 2020 later on\n",
    "start = dt.date(2020, 10, 1)\n",
    "end = dt.date(2020, 10, 13)\n",
    "bursts_file = \"/home/jonathanbahlmann/Public/coherence-docs/src/reference_bursts.geojson\"\n",
    "aoi_file = \"/home/jonathanbahlmann/Public/coherence-docs/aoi/belgium_france.geojson\"\n",
    "\n",
    "create_reference_scene_json(start = start, end = end, aoi_file = aoi_file, bursts_file = bursts_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8850da-db2a-4a26-869f-29e7cf9289cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33fab3-cef6-4cac-afb1-e56d2677beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from util import list_days\n",
    "\n",
    "# 2021/07/03 - 2021/09/10\n",
    "start  = \"2021/07/03\"\n",
    "end = \"2021/11/10\"\n",
    "path = \"/data/MTDA/CGS_S1/CGS_S1_SLC_L1/IW/DV/\"\n",
    "\n",
    "def list_products_by_time(start, end, path = \"/data/MTDA/CGS_S1/CGS_S1_SLC_L1/IW/DV/\"):\n",
    "    s_month = int(start[5:7])\n",
    "    e_month = int(end[5:7])\n",
    "    s_day = int(start[8:])\n",
    "    e_day = int(end[8:])\n",
    "\n",
    "    start_folder = path + start[0:7] # year and month, no /\n",
    "    end_folder = path + end[0:7]\n",
    "\n",
    "    # if only in one month\n",
    "    if s_month == e_month:\n",
    "        start_folder_days = os.listdir(start_folder)[s_day-1:e_day] # list days, from start day : end day\n",
    "        list_of_products = list_days(list_of_days = start_folder_days, month_path = start_folder)\n",
    "    # no in between month\n",
    "    elif s_month + 1 == e_month:\n",
    "        start_folder_days = os.listdir(start_folder)[s_day-1:] # list days, from start day\n",
    "        end_folder_days = os.listdir(end_folder)[:e_day]\n",
    "        list_of_products = list_days(start_folder_days, start_folder) + list_days(end_folder_days, end_folder)\n",
    "    # with month in between\n",
    "    elif s_month +1 < e_month:\n",
    "        start_folder_days = os.listdir(start_folder)[s_day-1:]\n",
    "        end_folder_days = os.listdir(end_folder)[:e_day]\n",
    "        list_of_products = list_days(start_folder_days, start_folder) + list_days(end_folder_days, end_folder)\n",
    "\n",
    "        for i in range(s_month+1,e_month):\n",
    "            if i < 10:\n",
    "                month = \"0\" + str(i)\n",
    "            elif i >= 10:\n",
    "                month = str(i)\n",
    "\n",
    "            month_path = os.path.join(path, start[0:5], month)\n",
    "            month_days_list = os.listdir(month_path)\n",
    "            month_prod_list = list_days(month_days_list, month_path)\n",
    "            list_of_products.extend(month_prod_list)\n",
    "        \n",
    "    return list_of_products\n",
    "\n",
    "# print(list_days([\"01\", \"02\", \"03\"], path + \"2021/08\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ebc4b58-1990-4c4b-b2a5-bca77560704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_reference(scene_gpd, ref_gpd, ref_sensor: str = \"S1A\", epsg: int = 32631):\n",
    "    \"\"\"This function searches for the set of eligible reference scenes for coregistration.\n",
    "    \n",
    "    If no scene is found, something is off.\n",
    "    If one scene is found, it should be from the same sensor.\n",
    "    If two scenes are found, it should be a different sensor.\n",
    "    :param scene_gpd: gpd of scene to search a reference for\n",
    "    :param ref_gpd: gpd with reference bursts\n",
    "    :param ref_sensor: sensor of ref_gpd\n",
    "    :param epsg: EPSG CRS to convert to for area calculation\n",
    "    \"\"\"\n",
    "    epsg_str = 'epsg:' + str(epsg)\n",
    "    \n",
    "    scene_gpd = scene_gpd.dissolve(\"subswath\", as_index = False)\n",
    "    # scene_gpd.to_file(\"scene_gpd_check_\" + str(scene_gpd.iloc[0][\"id\"]) + \".geojson\", driver = \"GeoJSON\")\n",
    "    scene_sensor = scene_gpd.iloc[0][\"sensor\"]\n",
    "    rel_o = scene_gpd.iloc[0][\"rel_orbit\"]\n",
    "    o_dir = scene_gpd.iloc[0][\"orbit_direction\"]\n",
    "    # search in existing table for bursts of the same relative orbit and orbit direction\n",
    "    ref_gpd_same_orbit = ref_gpd.loc[(ref_gpd[\"rel_orbit\"] == rel_o) & (ref_gpd[\"orbit_direction\"] == o_dir)]\n",
    "    \n",
    "    # if scenes from the same orbit are found\n",
    "    if not ref_gpd_same_orbit.empty:\n",
    "        ref_gpd_same_orbit = ref_gpd_same_orbit.dissolve([\"id\", \"subswath\"], as_index = False)\n",
    "        \n",
    "        # calculate intersection\n",
    "        intersection = gpd.overlay(ref_gpd_same_orbit, scene_gpd, how = \"intersection\") # so id_1 is different each intersection\n",
    "\n",
    "        if not intersection.empty:\n",
    "\n",
    "            intersection[\"area\"] = intersection.to_crs({'init': epsg_str}).area\n",
    "\n",
    "            # intersection.to_file(\"intersection\" + str(intersection.iloc[0][\"id_2\"]) + \".geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "            # filter intersection for geometries larger or equal to the size of a single burst\n",
    "            burst_size = 1800000000.0\n",
    "            intersection = intersection.loc[intersection[\"area\"] > burst_size]\n",
    "            \n",
    "            if not intersection.empty:\n",
    "\n",
    "                if scene_sensor == ref_sensor:\n",
    "                    #intersection.to_file(\"intersection.geojson\", driver=  \"GeoJSON\")\n",
    "                    #scene_gpd.to_file(\"scene_gpd.geojson\", driver=\"GeoJSON\")\n",
    "                    # intersection should now contain only one specific id_1\n",
    "                    # print(intersection[[\"id_2\", \"subswath_2\", \"burst_2\", \"area\", \"id_1\", \"subswath_1\", \"burst_1\"]])\n",
    "                    subs = set(intersection[\"subswath_1\"].array)\n",
    "                    return {intersection.iloc[0].loc[\"id_1\"]: list(subs)}\n",
    "                else:\n",
    "                    # print(intersection[[\"id_2\", \"subswath_2\", \"burst_2\", \"area\", \"id_1\", \"subswath_1\", \"burst_1\"]])            \n",
    "                    # make set of id_1 column\n",
    "                    ids = set(intersection[\"id_1\"].array)\n",
    "                    # search for each id for involved subswaths\n",
    "                    subs_dict = {}\n",
    "                    for id in ids:\n",
    "                        subs = intersection.loc[intersection[\"id_1\"] == id][\"subswath_1\"].array\n",
    "                        # in intersection, burst info is lost..\n",
    "                        subs_dict[id] = list(subs)\n",
    "                    # print(subs_dict)\n",
    "                    return subs_dict\n",
    "                    # 1.825593e+09 is in\n",
    "                    # 2.075e-09 is in, 1.569e-09 (full subswath side intersection) is out\n",
    "                    # 1.814e-09 is in, one burst, same sensor\n",
    "                    \n",
    "            else:\n",
    "                return {}\n",
    "            \n",
    "    # when no intersection, return empty array\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "75c026ec-fa6a-4662-8afd-07241cb079db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_bursts_file not found\n",
      "{'6471': ['IW2', 'IW1', 'IW3']}\n",
      "6471 IW2\n",
      "6471 IW1\n",
      "6471 IW3\n",
      "{'3785': ['IW2', 'IW1', 'IW3']}\n",
      "3785 IW2\n",
      "3785 IW1\n",
      "3785 IW3\n",
      "{'ACC4': ['IW2', 'IW1', 'IW3']}\n",
      "ACC4 IW2\n",
      "ACC4 IW1\n",
      "ACC4 IW3\n",
      "{'7BC8': ['IW3']}\n",
      "7BC8 IW3\n",
      "{'9F0A': ['IW2', 'IW1', 'IW3'], '4712': ['IW2', 'IW1', 'IW3']}\n",
      "9F0A IW2\n",
      "9F0A IW1\n",
      "9F0A IW3\n",
      "4712 IW2\n",
      "4712 IW1\n",
      "4712 IW3\n",
      "{'9F0A': ['IW3', 'IW2', 'IW1'], '7BC8': ['IW3', 'IW2']}\n",
      "9F0A IW3\n",
      "9F0A IW2\n",
      "9F0A IW1\n",
      "7BC8 IW3\n",
      "7BC8 IW2\n",
      "{'1F6C': ['IW2', 'IW3']}\n",
      "1F6C IW2\n",
      "1F6C IW3\n",
      "{'7E94': ['IW2', 'IW1', 'IW3']}\n",
      "7E94 IW2\n",
      "7E94 IW1\n",
      "7E94 IW3\n",
      "{}\n",
      "{}\n",
      "{'AAC4': ['IW1', 'IW2', 'IW3'], '3F3B': ['IW2', 'IW3']}\n",
      "AAC4 IW1\n",
      "AAC4 IW2\n",
      "AAC4 IW3\n",
      "3F3B IW2\n",
      "3F3B IW3\n",
      "{'AAC4': ['IW1', 'IW2', 'IW3']}\n",
      "AAC4 IW1\n",
      "AAC4 IW2\n",
      "AAC4 IW3\n",
      "{}\n",
      "{'FB38': ['IW2', 'IW1', 'IW3']}\n",
      "FB38 IW2\n",
      "FB38 IW1\n",
      "FB38 IW3\n",
      "{'14F6': ['IW2', 'IW1', 'IW3']}\n",
      "14F6 IW2\n",
      "14F6 IW1\n",
      "14F6 IW3\n",
      "{'314F': ['IW2', 'IW1', 'IW3']}\n",
      "314F IW2\n",
      "314F IW1\n",
      "314F IW3\n",
      "{'7AA0': ['IW1', 'IW2']}\n",
      "7AA0 IW1\n",
      "7AA0 IW2\n",
      "{'A8C7': ['IW1', 'IW2'], '7AA0': ['IW1', 'IW2']}\n",
      "A8C7 IW1\n",
      "A8C7 IW2\n",
      "7AA0 IW1\n",
      "7AA0 IW2\n",
      "{'A8C7': ['IW1', 'IW2', 'IW3']}\n",
      "A8C7 IW1\n",
      "A8C7 IW2\n",
      "A8C7 IW3\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from util import list_days, create_gpd_for_scene\n",
    "from preprocessing import *\n",
    "\n",
    "products = list_products_by_time(start = \"2021/09/06\", end = \"2021/09/10\")\n",
    "# we get 3 products for that day\n",
    "prod_file = \"\"\n",
    "\n",
    "if os.path.isfile(prod_file):\n",
    "    prod_gpd = gpd.read_file(prod_file)\n",
    "    create_new_file = False\n",
    "else:\n",
    "    print(\"ref_bursts_file not found\")\n",
    "    create_new_file = True\n",
    "    \n",
    "ref_bursts = gpd.read_file(\"reference_bursts.geojson\")\n",
    "\n",
    "new_busts = []\n",
    "    \n",
    "for path in products:\n",
    "    # make swath geometry and add basic info to df\n",
    "    scene_bursts = create_gpd_for_scene(path)\n",
    "    \n",
    "    if create_new_file: # not create_new_file:\n",
    "        \n",
    "        # search directly for ref scene\n",
    "        ref_scene_dict = search_for_reference(scene_bursts, ref_bursts)\n",
    "        \n",
    "        # decide which bursts need to be processed!\n",
    "        # iterate through subswaths of reference scenes\n",
    "        for id in [*ref_scene_dict]:\n",
    "            for subs in ref_scene_dict[id]:\n",
    "                print(id, subs)\n",
    "                #TODO\n",
    "        \n",
    "        scene_bursts[\"ref_ids\"] = str(ref_scene_ids) # solve with eval()\n",
    "        \n",
    "        # new_bursts.append(scene_bursts)  \n",
    "    \n",
    "    else:\n",
    "        # check if all bursts are in the file already\n",
    "        in_table = ref_bursts.loc[ref_bursts[\"id\"] == scene_bursts.loc[0][\"id\"]]\n",
    "        \n",
    "        # if in_table\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    # write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42cda88b-412b-479a-ad2e-3a2ace302bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in [\"3\",\"4\",\"5\"]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4fde56-a264-4379-9107-7ddcef86f5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PandasArray>\n",
       "['de', 'fe']\n",
       "Length: 2, dtype: str64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"b\": pd.array([\"de\", \"fe\"])}\n",
    "a[\"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cebf6b2-ffd1-447f-b3b0-4e19e0d4c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [\"01\", \"02\"]\n",
    "l2 = [\"01\", \"03\"]\n",
    "set(l1) == set(l2)\n",
    "set(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda69e1-6362-4658-9779-3ea1b81bc6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
