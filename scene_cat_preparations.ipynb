{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62465d-9eb2-4561-bb29-910e1bab8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query Terrascope archive using terracatalgoueclient\n",
    "from terracatalogueclient import Catalogue\n",
    "import datetime as dt\n",
    "\n",
    "# processes only VV\n",
    "\n",
    "# define name of result\n",
    "name = \"testRun_01\"\n",
    "\n",
    "catalogue = Catalogue()\n",
    "\n",
    "import glob\n",
    "from pyroSAR import identify\n",
    "import stsa\n",
    "import pandas as pd\n",
    "import sys, os\n",
    "from contextlib import contextmanager\n",
    "import geopandas as gpd\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    # source http://thesmithfam.org/blog/2012/10/25/temporarily-suppress-console-output-in-python/\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5998b51-8798-4f72-bc56-84e0dd228ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f4277c-c617-422a-9ae6-fd30fe8faa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give one date, find closest acqusition before and after\n",
    "start = dt.date(2020, 10, 1) # input\n",
    "end = dt.date(2020, 10, 13)\n",
    "\n",
    "print(\"[CATALOGUE]: starting search for scenes...\")\n",
    "\n",
    "# first search\n",
    "cat = catalogue.get_products(\n",
    "\t\"urn:eop:VITO:CGS_S1_SLC_L1\",\n",
    "\tstart = start,\n",
    "\tend = end)\n",
    "\n",
    "s1a = []\n",
    "s1b = []\n",
    "\n",
    "for p in cat:\n",
    "    path = p.data[0].href \n",
    "    iw_index = path.index(\"IW\")\n",
    "    vm_path = \"/data/MTDA/CGS_S1/CGS_S1_SLC_L1/\" + path[iw_index:]\n",
    "\n",
    "    # make swath geometry and add basic info to df\n",
    "    ana_split = stsa.TopsSplitAnalyzer(target_subswaths=['iw1', 'iw2', 'iw3'])\n",
    "    with suppress_stdout():\n",
    "        ana_split.load_data(zip_path = vm_path)\n",
    "        ana_split._create_subswath_geometry()\n",
    "    ana_split = ana_split.df\n",
    "    pyro = identify(vm_path)\n",
    "    ana_split[\"sensor\"] = pyro.sensor\n",
    "    ana_split[\"start\"] = pyro.start\n",
    "    ana_split[\"rel_orbit\"] = pyro.orbitNumber_rel\n",
    "    \n",
    "    # append to list based on satellite\n",
    "    if pyro.sensor == \"S1A\":\n",
    "        s1a.append(ana_split)\n",
    "    elif pyro.sensor == \"S1B\":\n",
    "        s1b.append(ana_split)\n",
    "    \n",
    "s1a_df = gpd.GeoDataFrame(pd.concat(s1a, ignore_index = True), crs=s1a[0].crs)\n",
    "s1b_df = gpd.GeoDataFrame(pd.concat(s1b, ignore_index = True), crs=s1b[0].crs)\n",
    "\n",
    "aoi = gpd.read_file(\"/home/jonathanbahlmann/Public/coherence-docs/aoi/belgium_france.geojson\")\n",
    "\n",
    "# s1a_df.clip(aoi)\n",
    "# s1b_df.clip(aoi)\n",
    "print(s1a_df)\n",
    "print(aoi)\n",
    "# https://geopandas.org/en/stable/gallery/plot_clip.html\n",
    "\n",
    "s1a_df.dissolve([\"subswath\", \"start\"], as_index = False).to_file(\"snapshot_init_oct_1-13_10_21_S1A_scenes.geojson\", driver = \"GeoJSON\")\n",
    "s1b_df.dissolve([\"subswath\", \"start\"], as_index = False).to_file(\"snapshot_init_oct_1-13_10_21_S1B_scenes.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd7164-235d-42af-a3ec-34046013f57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea9e115-9b88-47ef-8744-065c59352862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gpd_for_scene(path, id, name, all_scenes):\n",
    "    \"\"\"Create a geopandas dataframe for a S1 scene.\n",
    "    \n",
    "    Metadata is read using pyroSAR. Creates the gpd using stsa.\n",
    "    A gpd with all bursts is returned.\n",
    "    \"\"\"\n",
    "    \n",
    "    # use pyroSAR to extract metadata\n",
    "    pyro = identify(path)\n",
    "\n",
    "    # use stsa to create swath geometry\n",
    "    stsa_geom = stsa.TopsSplitAnalyzer(target_subswaths=['iw1', 'iw2', 'iw3'])\n",
    "    with suppress_stdout():\n",
    "        stsa_geom.load_data(zip_path = path)\n",
    "        stsa_geom._create_subswath_geometry()\n",
    "\n",
    "    # add attributes to bursts\n",
    "    stsa_geom = stsa_geom.df\n",
    "    stsa_geom[\"id\"] = id\n",
    "    stsa_geom[\"name\"] = name\n",
    "    stsa_geom[\"path\"] = path\n",
    "    stsa_geom[\"sensor\"] = pyro.sensor\n",
    "    stsa_geom[\"polarizations\"] = ','.join(str(e) for e in pyro.polarizations)\n",
    "    stsa_geom[\"start\"] = pyro.start\n",
    "    stsa_geom[\"stop\"] = pyro.stop\n",
    "    stsa_geom[\"mode\"] = pyro.acquisition_mode\n",
    "    stsa_geom[\"product\"] = pyro.product\n",
    "    stsa_geom[\"orbit_direction\"] = pyro.orbit\n",
    "    stsa_geom[\"rel_orbit\"] = pyro.orbitNumber_rel\n",
    "\n",
    "    # check whether the scene has a regular burst pattern (no missing, no additional bursts)\n",
    "    if stsa_geom.loc[:,\"burst\"].to_list() == [1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9]:\n",
    "        stsa_geom[\"regular_burst_pattern\"] = 1\n",
    "    else:\n",
    "        stsa_geom[\"regular_burst_pattern\"] = 0\n",
    "\n",
    "    # TODO calc overlap etc.\n",
    "    orbit = pyro.orbitNumber_rel\n",
    "    direction = pyro.orbit\n",
    "    \n",
    "    all_from_orbit = all_scenes[all_scenes[\"rel_orbit\"] == orbit]\n",
    "    intersection = gpd.overlay(stsa_geom, all_from_orbit, how = \"intersection\")\n",
    "    intersection = intersection.dissolve([\"id_2\", \"subswath_2\"], as_index = False)\n",
    "    print(intersection)\n",
    "    intersection.to_file(\"intersec.geojson\", driver=\"GeoJSON\")\n",
    "    \n",
    "    return(stsa_geom)\n",
    "\n",
    "# introduce geojson\n",
    "file_list = glob.glob(\"/data/MTDA/CGS_S1/CGS_S1_SLC_L1/IW/DV/2021/09/07/*/*.zip\")\n",
    "\n",
    "# load main dataframe\n",
    "if os.path.isfile(\"scene_processing.geojson\"):\n",
    "    all_scenes = gpd.read_file(\"scene_processing.geojson\")\n",
    "    create_new_file = False\n",
    "    \n",
    "    # create a dataframe with a geometry for each subswath of each scene\n",
    "    # all_scenes.dissolve([\"id\", \"subswath\"], as_index = False).to_file(\"diss_id_subs.geojson\", driver = \"GeoJSON\")\n",
    "    \n",
    "else:\n",
    "    print(\"scene_processing.geojson not found\")\n",
    "    create_new_file = True\n",
    "\n",
    "new_list = []\n",
    "\n",
    "for path in file_list:\n",
    "    name = path[path.rfind(\"/\")+1:len(path)-4] # extract product name from path\n",
    "    id = name[len(name)-4:len(name)]\n",
    "    \n",
    "    if create_new_file:\n",
    "        stsa_geom = create_gpd_for_scene(path, id, name, all_scenes)\n",
    "        # append to geodataframe list\n",
    "        new_list.append(stsa_geom)\n",
    "    \n",
    "    elif not id in all_scenes[\"id\"].values:\n",
    "        # print(\"found new scene\")\n",
    "        stsa_geom = create_gpd_for_scene(path, id, name, all_scenes)\n",
    "\n",
    "        # append to geodataframe list\n",
    "        new_list.append(stsa_geom)\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "        # print(\"old scene\")\n",
    "    \n",
    "    \n",
    "    \n",
    "# print(set(pd.DataFrame(meta_list)[\"rel_orbit\"].to_list()))\n",
    "# orbits of the year 2021 are {1, 8, 37, 59, 88, 101, 110, 137, 139, 161} # ASF: 1, 101, 137 doesnt seem to exist over belgium\n",
    "# found in 11 day baseline: {8, 37, 59, 88, 110, 139, 161}\n",
    "\n",
    "def save_gpd(all_scenes, geodf, flag):\n",
    "    \"\"\"Saves a geopandas dataframe to a file.\n",
    "    \n",
    "    If a new file should be created, there is nothing to merge into.\n",
    "    \"\"\"\n",
    "    \n",
    "    if flag:\n",
    "        geodf.to_file(\"scene_processing.geojson\", driver = \"GeoJSON\")\n",
    "    else:\n",
    "        all_scenes = all_scenes.append(geodf, sort = False)\n",
    "        all_scenes.to_file(\"scene_processing_all.geojson\", driver = \"GeoJSON\")\n",
    "\n",
    "if len(new_list) > 1:\n",
    "    new_df = gpd.GeoDataFrame(pd.concat(new_list, ignore_index = True), crs=new_list[0].crs)\n",
    "    save_gpd(all_scenes, new_df, create_new_file)\n",
    "    print(int(len(new_df)/27), \" new scenes added\")\n",
    "elif len(new_list) == 1:\n",
    "    save_gpd(all_scenes, new_list[0], create_new_file)\n",
    "    print(\"1 new scene added\")\n",
    "else:\n",
    "    print(\"no new scenes found\")\n",
    "    pass # nothing needs to be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e0a12c-927b-4ea2-b816-07aa11a338eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file(\"scene_processing.geojson\")\n",
    "df = df.dissolve(\"id\", as_index = False)\n",
    "df.to_file(\"whole_scenes_09_1-2.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2bba75-e2d0-4cec-9b4d-6804325adf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e02195-8246-4aa8-b08e-04ef7fc52d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 4, 16, 0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing area\n",
    "import datetime as dt\n",
    "dt.datetime.strptime(\"19/04/2020\", \"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5a0f6-9d29-4aac-a385-7fe0f9256d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
